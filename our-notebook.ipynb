{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4ef79b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ipdb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5aecdc9391ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ipdb'"
     ]
    }
   ],
   "source": [
    "import ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f313fd07",
   "metadata": {},
   "source": [
    "# Data generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaa7faa",
   "metadata": {},
   "source": [
    "## Environment and robot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our robot is a shaped as a 2d planar box with size equals to 0.2 meters. It can move simultaneously both horizontally and vertically. Therefore, its configuration space is a 2d rectangle which size is determined by the maze size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyPlanarRobot():\n",
    "    def __init__(self, base_xy_bounds=5.0) -> None:\n",
    "        self.num_dim = 2\n",
    "        self.joint_idx=[0,1]\n",
    "        self.size = 0.2\n",
    "\n",
    "        self.joint_bounds = []\n",
    "        self.joint_bounds.append([-base_xy_bounds, base_xy_bounds]) # x\n",
    "        self.joint_bounds.append([-base_xy_bounds, base_xy_bounds]) # y\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def get_joint_bounds(self):\n",
    "        return self.joint_bounds\n",
    "\n",
    "    def get_joint_lower_bounds(self):\n",
    "        robot_bounds_low = [bound[0] for bound in self.joint_bounds]\n",
    "        return robot_bounds_low\n",
    "\n",
    "    def get_joint_higher_bounds(self):\n",
    "        robot_bounds_high = [bound[1] for bound in self.joint_bounds]\n",
    "        return robot_bounds_high\n",
    "\n",
    "    def get_cur_state(self):\n",
    "        return self.state\n",
    "\n",
    "    def set_state(self, state):\n",
    "        self.state = state\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = [0] * self.num_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our environment is a 2d maze with size 5m * 5m. It is filled with random generated square obstacles of fixed size 1m * 1m.  The difficulties of the maze can be manipulated by altering the number of obstacles present. The maze can be visualized by an occupancy grid with resolution 0.5m, making it essentially an image of size 10 x 10. \n",
    "\n",
    "To facilitate path planning, the maze class also contains code to sample valid start and goals of the point robot and perform collision checking for a given robot configuration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8dd910d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import json\n",
    "import sys\n",
    "import os.path as osp\n",
    "\n",
    "# -------------- Settings ----------------\n",
    "RANDOM = True\n",
    "TOTAL_START_GOAL_CNT = 50\n",
    "MAZE_SIZE = 5\n",
    "OCC_GRID_RESOLUTION = 0.1\n",
    "SMALL_OCC_GRID_RESLUTION = 0.5\n",
    "\n",
    "class Maze2D():\n",
    "    def __init__(self):\n",
    "        self.obstacles = []\n",
    "\n",
    "        # load robot\n",
    "        robot = MyPlanarRobot(base_xy_bounds = MAZE_SIZE / 2.0)\n",
    "        self.robot = robot\n",
    "\n",
    "        # 2d occupancy grid\n",
    "        self.occ_grid_size = int(MAZE_SIZE / OCC_GRID_RESOLUTION)\n",
    "        self.occ_grid = np.zeros((self.occ_grid_size, self.occ_grid_size), dtype=np.uint8)\n",
    "        self.small_occ_grid_size = int(MAZE_SIZE / SMALL_OCC_GRID_RESLUTION)\n",
    "\n",
    "        # clear obstacles\n",
    "        self.clear_obstacles()\n",
    "\n",
    "        # add surrounding walls\n",
    "        half_size = MAZE_SIZE / 2.0\n",
    "        # add wall\n",
    "        self.add_box([half_size + 0.1, 0, 1], [0.1, half_size, 1])\n",
    "        self.add_box([-half_size - 0.1, 0, 1], [0.1, half_size, 1])\n",
    "        self.add_box([0, half_size + 0.1, 1], [half_size, 0.1, 1])\n",
    "        self.add_box([0, -half_size - 0.1, 1], [half_size, 0.1, 1])\n",
    "\n",
    "        # internal attributes\n",
    "        self.goal_robot_id = None\n",
    "        self.path = None\n",
    "        self.approx_path = None\n",
    "        self.sg_pairs = None\n",
    "\n",
    "    def clear_obstacles(self):\n",
    "        self.occ_grid.fill(0)\n",
    "        self.obstacle_dict = {}\n",
    "        self.inflated_occ_grid = None\n",
    "\n",
    "    def random_obstacles(self, num_of_boxes = 8):\n",
    "        # add random obstacles with boxes.\n",
    "        # box_positions = [(-2.25, 2.25)]\n",
    "        box_positions = []\n",
    "\n",
    "        for _ in range(num_of_boxes):\n",
    "            x = random.randint(0, 4)\n",
    "            y = random.randint(0, 4)\n",
    "            x = x - 2\n",
    "            y = y - 2\n",
    "            box_positions.append((x, y))\n",
    "\n",
    "        # print(box_positions)\n",
    "        for box_pos in box_positions:\n",
    "            self.add_box([box_pos[0], box_pos[1], 0.5], [0.5, 0.5, 0.5])\n",
    "\n",
    "        self.obstacle_dict[\"box\"] = box_positions\n",
    "\n",
    "        self.get_inflated_occ_grid()\n",
    "\n",
    "    def add_box(self, box_pos, half_box_size):\n",
    "        # for occupancy grid, center is at upper left corner, unit is cm\n",
    "        half_size = MAZE_SIZE / 2.0\n",
    "        tmp = int(1 / OCC_GRID_RESOLUTION)\n",
    "        cx = (-box_pos[1] + half_size) * tmp\n",
    "        cy = (box_pos[0] + half_size) * tmp\n",
    "        x_size = half_box_size[1] * tmp\n",
    "        y_size = half_box_size[0] * tmp\n",
    "        for x in range(max(0, int(cx - x_size)), min(self.occ_grid_size, int(cx + x_size))):\n",
    "            for y in range(max(0, int(cy - y_size)), min(self.occ_grid_size, int(cy + y_size))):\n",
    "                self.occ_grid[x, y] = 1\n",
    "\n",
    "    def get_occupancy_grid(self):\n",
    "        return self.occ_grid\n",
    "\n",
    "    def get_small_occupancy_grid(self):\n",
    "        occ_grid_small = np.zeros((self.small_occ_grid_size, self.small_occ_grid_size), dtype=np.int8)\n",
    "        for i in range(self.small_occ_grid_size):\n",
    "            for j in range(self.small_occ_grid_size):\n",
    "                occ_grid_small[i, j] = (np.max(self.occ_grid[i*5:(i+1)*5, j*5:(j+1)*5]) == 1)\n",
    "\n",
    "        return occ_grid_small\n",
    "\n",
    "    def get_obstacle_dict(self):\n",
    "        return self.obstacle_dict.copy()\n",
    "\n",
    "    def load_obstacle_dict(self, obstacle_dict):\n",
    "        if \"box\" in obstacle_dict:\n",
    "            for box_pos in obstacle_dict[\"box\"]:\n",
    "                self.add_box([box_pos[0], box_pos[1], 0.5], [0.5, 0.5, 0.5])\n",
    "\n",
    "        self.obstacle_dict = obstacle_dict\n",
    "\n",
    "    def sample_start_goal(self):\n",
    "        while True:\n",
    "            start = [0] * self.robot.num_dim\n",
    "            goal = [0] * self.robot.num_dim\n",
    "            low_bounds = self.robot.get_joint_lower_bounds()\n",
    "            high_bounds = self.robot.get_joint_higher_bounds()\n",
    "            for i in range(self.robot.num_dim):\n",
    "                start[i] = random.uniform(low_bounds[i], high_bounds[i])\n",
    "                goal[i] = random.uniform(low_bounds[i], high_bounds[i])\n",
    "\n",
    "            if self.is_state_valid(start) and self.is_state_valid(goal):\n",
    "                self.start = start\n",
    "                self.goal = goal\n",
    "                break\n",
    "\n",
    "        print(\"Maze2d: start: {}\".format(self.start))\n",
    "        print(\"Maze2d: goal: {}\".format(self.goal))\n",
    "\n",
    "    def get_inflated_occ_grid(self):\n",
    "        if self.inflated_occ_grid is None:\n",
    "            tmp = np.zeros((self.occ_grid_size + 2, self.occ_grid_size + 2), dtype=np.uint8)\n",
    "            tmp[:self.occ_grid_size, :self.occ_grid_size] += self.occ_grid\n",
    "            tmp[1:self.occ_grid_size + 1, :self.occ_grid_size] += self.occ_grid\n",
    "            tmp[2:, :self.occ_grid_size] += self.occ_grid\n",
    "            tmp[:self.occ_grid_size, 1:self.occ_grid_size+1] += self.occ_grid\n",
    "            tmp[1:self.occ_grid_size + 1, 1:self.occ_grid_size+1] += self.occ_grid\n",
    "            tmp[2:, 1:self.occ_grid_size+1] += self.occ_grid\n",
    "            tmp[:self.occ_grid_size, 2:] += self.occ_grid\n",
    "            tmp[1:self.occ_grid_size + 1, 2:] += self.occ_grid\n",
    "            tmp[2:, 2:] += self.occ_grid\n",
    "            tmp[tmp > 0] = 1\n",
    "\n",
    "            self.inflated_occ_grid = tmp[1:self.occ_grid_size + 1, 1:self.occ_grid_size + 1]\n",
    "\n",
    "    def is_state_valid(self, robot_state):\n",
    "        # Inflate obstacle for collision checking\n",
    "        self.get_inflated_occ_grid()\n",
    "\n",
    "        y, x = robot_state[0], robot_state[1]\n",
    "        x = int((MAZE_SIZE / 2.0 - x) / 0.1)\n",
    "        y = int((y + MAZE_SIZE / 2.0) / 0.1)\n",
    "\n",
    "        res = (self.inflated_occ_grid[x, y] != 1)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate a random environment and sample a random start and goal configuration of the robot and visualize the problem. The start configuration is shown in yellow and the goal configuration is shown in red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maze2d: start: [-1.7337804889263038, 0.6677984352276205]\n",
      "Maze2d: goal: [-2.0924252128314027, -2.0845208967241207]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def visualize_data(occ_g, start_pos, goal_pos):\n",
    "    occ_g = np.array(occ_g).reshape(10, 10)\n",
    "    fig, ax = plt.subplots(1, figsize=(10, 10), dpi=100)\n",
    "    occ_grid_size = occ_g.shape[0]\n",
    "    tmp = occ_grid_size / 4.0 - 0.25\n",
    "    s = (10.0 / occ_grid_size * 100 / 2) ** 2 + 500\n",
    "    for i in range(occ_grid_size):\n",
    "        for j in range(occ_grid_size):\n",
    "            if occ_g[i,j] == 1:\n",
    "                plt.scatter(j/2.0 - tmp, tmp - i/2.0, color=\"black\", marker='s', s=s, alpha=1) # init\n",
    "\n",
    "    ax.add_patch(patches.Rectangle((start_pos[0]-0.1, start_pos[1]-0.1), 0.2, 0.2, facecolor='y'))\n",
    "    ax.add_patch(patches.Rectangle((goal_pos[0]-0.1, goal_pos[1]-0.1), 0.2, 0.2, facecolor='r'))\n",
    "                \n",
    "    ax.set_title(\"Visualization\")\n",
    "    ax.set_xlim(-2.5, 2.5)\n",
    "    ax.set_ylim(-2.5, 2.5)\n",
    "\n",
    "maze = Maze2D()\n",
    "maze.random_obstacles()\n",
    "maze.sample_start_goal()\n",
    "\n",
    "occ_grid = maze.get_small_occupancy_grid()\n",
    "visualize_data(occ_grid, maze.start, maze.goal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data from Expert Path Planner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a neural path planner, we need to generate a database of path planned by an expert path planner. There are numerous choices of path planners we can use. In this particular case, since our robot state is continuous, we choose to use the classic PRM motion planner. It firstly samples valid configurations of robot uniformly in the whole space and attempts to connect those configurations if the path between the states are collision-free. It results in a dense roadmap that captures the connectivity of the space. Finally, a discrete motion planner such as A* is used to find a path between a given start and goal configurations in the space. Another reason that PRM is particularly useful here is that it is multi-query planner, meaning the generated roadmap can be used to solve multiple queries of different start and goal configurations. \n",
    "\n",
    "To generate our path dataset, we sample 200 different mazes with number of obstacles ranging from 5 to 14. In each environment, we sample 500 random configurations and attempt to connect all valid configurations. We save the resultant roadmap as a networkx graph. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "maze = Maze2D()\n",
    "\n",
    "env_num = 200\n",
    "\n",
    "sparse_num = 100\n",
    "dense_num = 500\n",
    "\n",
    "for i in range(env_num):\n",
    "    # save\n",
    "    directory = osp.join(\"./dataset/{}\".format(i))\n",
    "    if not osp.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    num_of_boxes = 5 + i // 50\n",
    "\n",
    "    # env\n",
    "    maze.clear_obstacles()\n",
    "    maze.random_obstacles(num_of_boxes=num_of_boxes)\n",
    "    occ_grid = np.array(maze.get_occupancy_grid()).reshape(50, 50)\n",
    "    occ_grid_small = maze.get_small_occupancy_grid()\n",
    "    obstacle_dict = maze.get_obstacle_dict()\n",
    "    maze.sample_start_goal()\n",
    "    maze.robot.set_state(maze.start)\n",
    "\n",
    "    # dense states\n",
    "    states = []\n",
    "    col_status = []\n",
    "    low = maze.robot.get_joint_lower_bounds()\n",
    "    high = maze.robot.get_joint_higher_bounds()\n",
    "    for _ in range(dense_num):\n",
    "        random_state = [0] * maze.robot.num_dim\n",
    "        for i in range(maze.robot.num_dim):\n",
    "            random_state[i] = random.uniform(low[i], high[i])\n",
    "        col_status.append(maze.is_state_valid(random_state)) # mark collision states\n",
    "        states.append(random_state)\n",
    "\n",
    "    dense_G = nx.DiGraph()\n",
    "    dense_G.add_nodes_from([(\"n{}\".format(i), {\"coords\": ','.join(map(str, state)), \"col\": not col_status[i]}) for i, state in enumerate(states)])\n",
    "\n",
    "    # save\n",
    "    # node_pos = np.array(states)\n",
    "    node_pos = np.array([utils.state_to_numpy(dense_G.nodes[node]['coords']) for node in dense_G.nodes()])\n",
    "    utils.visualize_nodes(occ_grid_small, node_pos, None, None, show=False, save=True, file_name=osp.join(directory, \"dense.png\"))\n",
    "    node_pos = np.array([utils.state_to_numpy(dense_G.nodes[node]['coords']) for node in dense_G.nodes() if not dense_G.nodes[node]['col']])\n",
    "    utils.visualize_nodes(occ_grid_small, node_pos, None, None, show=False, save=True, file_name=osp.join(directory, \"dense_free.png\"))\n",
    "\n",
    "    print(\"connecting dense graph\")\n",
    "    nodes = dense_G.nodes()\n",
    "    node_pairs = itertools.combinations(nodes, 2)\n",
    "    # print(list(node_pairs))\n",
    "    for node_pair in node_pairs:\n",
    "        if not dense_G.has_edge(node_pair[0], node_pair[1]):\n",
    "            s1 = dense_G.nodes[node_pair[0]]['coords']\n",
    "            s2 = dense_G.nodes[node_pair[1]]['coords']\n",
    "            if utils.is_edge_free(maze, s1, s2):\n",
    "                dense_G.add_edge(node_pair[0], node_pair[1])\n",
    "                dense_G.add_edge(node_pair[1], node_pair[0])\n",
    "    for u,v in dense_G.edges:\n",
    "        dense_G[u][v]['weight'] = utils.calc_weight_states(dense_G.nodes[u]['coords'], dense_G.nodes[v]['coords'])\n",
    "\n",
    "    # save\n",
    "    nx.write_graphml(dense_G, osp.join(directory, \"dense_g.graphml\"))\n",
    "    with open(osp.join(directory, \"occ_grid.txt\"), 'w') as f:\n",
    "        np.savetxt(f, occ_grid_small.reshape(1, -1))\n",
    "    with open(osp.join(directory, \"obstacle_dict.json\"), 'w') as f:\n",
    "        json.dump(obstacle_dict, f)\n",
    "    utils.visualize_nodes(occ_grid_small, [], None, None, show=False, save=True, file_name=osp.join(directory, \"occ_grid.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generata Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to collect multiple paths from a single generated environment. Therefore, we first load the saved roadmap graph, and subsequently nvoke Astar path planner to find shortest path between each possible pair of start and goal configurations. If a path is found, we add to our dataset.\n",
    "\n",
    "Here we ignore path that contains only 2 waypoints. Intuitively, a path with two waypoints means that the start configuration and goal configuration of the robot can be connected by a straigh line. As our environment is not very cluttered, the majority of the path in our dataset may constitute such a straight-line path. This imbalance might incur problems in the latter training stage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating paths in env 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-c6c4415eb131>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mgoal_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_to_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdense_G\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgoal_n\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'coords'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mpath_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdense_G\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mocc_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m# sanity check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/CS5242-neural-motion-planning/astar.py\u001b[0m in \u001b[0;36mastar\u001b[0;34m(G, start_v, goal_v, occ_g, row, col, inc, h_weight)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnext_cur\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;31m# dis_v = dis + compute_distance_id(G, cur, v)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdis_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdis\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcur\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0;31m# dis_v = dis + helper.calc_weight_states(G.nodes[cur]['coords'], G.nodes[v]['coords'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wbmp/lib/python3.8/site-packages/networkx/classes/coreviews.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_atlas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_atlas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "import sys\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "import utils\n",
    "\n",
    "import astar\n",
    "\n",
    "maze = Maze2D()\n",
    "\n",
    "env_num = 200\n",
    "sample_num = 500\n",
    "\n",
    "dataset = []\n",
    "for i in range(env_num):\n",
    "    print(\"generating paths in env {}\".format(i))\n",
    "    maze.clear_obstacles()\n",
    "\n",
    "    data_dir = \"./dataset/{}\".format(i)\n",
    "    with open(osp.join(data_dir, \"obstacle_dict.json\"), 'r') as f:\n",
    "        obstacle_dict = json.load(f)\n",
    "        maze.load_obstacle_dict(obstacle_dict)\n",
    "\n",
    "    dense_G = nx.read_graphml(osp.join(data_dir, \"dense_g.graphml\"))\n",
    "    occ_grid = np.loadtxt(osp.join(data_dir, \"occ_grid.txt\")).tolist()\n",
    "\n",
    "    # sample trajectories\n",
    "    for start_n in dense_G.nodes():\n",
    "        if dense_G.nodes[start_n]['col']:\n",
    "            continue\n",
    "\n",
    "        for goal_n in dense_G.nodes():\n",
    "            if dense_G.nodes[goal_n]['col']:\n",
    "                continue\n",
    "\n",
    "        goal_pos = utils.state_to_numpy(dense_G.nodes[goal_n]['coords']).tolist()\n",
    "        path_nodes, dis = astar.astar(dense_G, start_n, goal_n, occ_grid, None, None, None)\n",
    "\n",
    "        # sanity check\n",
    "        total_dist = 0\n",
    "        if len(path_nodes) > 2:\n",
    "            for i, node in enumerate(path_nodes):\n",
    "                if i < len(path_nodes) - 1:\n",
    "                    start_pos = utils.state_to_numpy(dense_G.nodes[node]['coords']).tolist()\n",
    "                    next_pos = utils.state_to_numpy(dense_G.nodes[path_nodes[i + 1]]['coords']).tolist()\n",
    "                    dist = utils.calc_weight_states(start_pos, next_pos)\n",
    "                    total_dist += dist\n",
    "            # print(total_dist, dis)\n",
    "            assert np.allclose(total_dist, dis)\n",
    "\n",
    "        if len(path_nodes) > 2:\n",
    "            path = []\n",
    "            for i, node in enumerate(path_nodes):\n",
    "                node_pos = utils.state_to_numpy(dense_G.nodes[node]['coords']).tolist()\n",
    "                path.append(node_pos)\n",
    "\n",
    "            dataset.append([start_pos, goal_pos, occ_grid, path])\n",
    "\n",
    "with open(\"./dataset/data_path.json\", 'w') as f:\n",
    "    json.dump(dataset, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset contains a paths, a sequence of waypoints. However, our MLP and CNN models predicts only the next waypoints given the current robot configuration. Therefore, the dataset needs to be further processed so that a single training data gives the next waypoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./dataset/data_path.json', 'r') as _file:\n",
    "    data_path = json.load(_file)\n",
    "\n",
    "dataset_waypoint = []\n",
    "for data_point in data_path:\n",
    "    start_pos, goal_pos, occ_grid, path = data_point\n",
    "    for i in range(1, len(path)):\n",
    "        prev_pos = path[i - 1]\n",
    "        current_pos = path[i]\n",
    "        dataset_waypoint.append([prev_pos, goal_pos, occ_grid, current_pos])\n",
    "\n",
    "with open(\"./dataset/data_waypoint.json\", 'w') as f:\n",
    "    json.dump(dataset_waypoint, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c44b554",
   "metadata": {},
   "source": [
    "# Visualization of the generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "523965c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "\n",
    "DATA_FILE_PATH_TO_LOAD = './dataset/data_waypoint.json'\n",
    "RAW_DATA = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db083bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_data(occ_g, current_pos, goal_pos, next_pos, predicted_pos=None):\n",
    "    occ_g = np.array(occ_g).reshape(10, 10)\n",
    "    fig, ax = plt.subplots(1, figsize=(10, 10), dpi=100)\n",
    "    occ_grid_size = occ_g.shape[0]\n",
    "    tmp = occ_grid_size / 4.0 - 0.25\n",
    "    s = (10.0 / occ_grid_size * 100 / 2) ** 2 + 500\n",
    "    for i in range(occ_grid_size):\n",
    "        for j in range(occ_grid_size):\n",
    "            if occ_g[i,j] == 1:\n",
    "                plt.scatter(j/2.0 - tmp, tmp - i/2.0, color=\"black\", marker='s', s=s, alpha=1) # init\n",
    "\n",
    "    ax.add_patch(patches.Rectangle((current_pos[0]-0.1, current_pos[1]-0.1), 0.2, 0.2, facecolor='y'))\n",
    "    ax.add_patch(patches.Rectangle((goal_pos[0]-0.1, goal_pos[1]-0.1), 0.2, 0.2, facecolor='r'))\n",
    "    ax.add_patch(patches.Rectangle((next_pos[0]-0.09, next_pos[1]-0.09), 0.18, 0.18, facecolor='g'))\n",
    "    if predicted_pos is not None:\n",
    "        ax.add_patch(patches.Rectangle((predicted_pos[0]-0.09, predicted_pos[1]-0.09), 0.18, 0.18, facecolor='b'))\n",
    "\n",
    "    ax.set_title(\"Visualization\")\n",
    "    ax.set_xlim(-2.5,2.5)\n",
    "    ax.set_ylim(-2.5,2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba77f9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RAW_DATA is None:\n",
    "    with open(DATA_FILE_PATH_TO_LOAD) as _file:\n",
    "        RAW_DATA = json.load(_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e90dc01",
   "metadata": {},
   "source": [
    "Randomly visualze a single data point.\n",
    "\n",
    "- Black: obstacles\n",
    "- Red: goal position\n",
    "- Yellow: current position\n",
    "- Green: the next position the robot should take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "502e2fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = np.random.randint(len(RAW_DATA))\n",
    "current_pos, goal_pos, occ_grid, next_pos, _, _ = RAW_DATA[idx]\n",
    "visualize_data(occ_grid, current_pos, goal_pos, next_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d73f4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0a7a066",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7980230b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fbda5a",
   "metadata": {},
   "source": [
    "## Definitions of networks and dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e9aeb8",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cee5e1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPDataset(Dataset):\n",
    "    \"\"\"A dataset class for the MLP.\n",
    "    \n",
    "    Input: A vector that concat current position, goal position and occupancy grid vector\n",
    "    Output: Next position\n",
    "    \"\"\"\n",
    "    def __init__(self, raw_data, transform=None, target_transform=None, device=\"cpu\"):\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.device = device\n",
    "        self.dataset = raw_data\n",
    "        print(\"dataset size = {}\".format(len(self.dataset)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start_pos, goal_pos, occ_grid, next_pos, non_connectable_nodes, dist = self.dataset[idx]\n",
    "\n",
    "        dim = len(start_pos)\n",
    "        start_pos = torch.Tensor(start_pos)\n",
    "        goal_pos = torch.Tensor(goal_pos)\n",
    "        occ_grid = torch.Tensor(occ_grid)\n",
    "        next_pos = torch.Tensor(next_pos)\n",
    "\n",
    "        input = torch.cat((start_pos, goal_pos, occ_grid), dim=0).to(self.device)\n",
    "        next_pos = next_pos.to(self.device)\n",
    "\n",
    "        return input, next_pos\n",
    "\n",
    "    @classmethod\n",
    "    def load_dataset_from_file(cls, file_path, device='cpu'):\n",
    "        print(\"Loading data from {}\".format(file_path))\n",
    "        with open(file_path, 'r') as f:\n",
    "            dataset = json.load(f)\n",
    "        return cls(dataset, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9227eae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPModel(nn.Module):\n",
    "    \"\"\"A trivially simple MLP model.\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(104, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return self.layers(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0ca71e",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135cb441",
   "metadata": {},
   "source": [
    "Choose the network and dataloader classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8387e74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_cls = MLPDataset\n",
    "network_cls = MLPModel\n",
    "criterion = torch.nn.MSELoss()\n",
    "model_save_path = './models/mlp.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191edde8",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74b1772f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size = 68957\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset_cls(RAW_DATA, device=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a616f6b",
   "metadata": {},
   "source": [
    "Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b8fa944",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPModel().to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdadb072",
   "metadata": {},
   "source": [
    "Run the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b46440e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(dataset) * 0.9)\n",
    "batch_size = 64\n",
    "learning_rate = 1e-4\n",
    "num_epochs=10\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b46dae64",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torch.utils.data.Subset(dataset, np.arange(train_size))\n",
    "val_set = torch.utils.data.Subset(dataset, np.arange(train_size, len(dataset)))\n",
    "train_dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "eval_dataloader = DataLoader(val_set, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93ac2dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------Total loss after mini-batch     0, epoch 0 : 1.511\n",
      "saved session to  ./models/mlp.pt\n",
      "-----------------Total loss after mini-batch   100, epoch 0 : 0.264\n",
      "-----------------Total loss after mini-batch   200, epoch 0 : 0.332\n",
      "-----------------Total loss after mini-batch   300, epoch 0 : 0.259\n",
      "-----------------Total loss after mini-batch   400, epoch 0 : 0.364\n",
      "-----------------Total loss after mini-batch   500, epoch 0 : 0.418\n",
      "saved session to  ./models/mlp.pt\n",
      "-----------------Total loss after mini-batch   600, epoch 0 : 0.262\n",
      "-----------------Total loss after mini-batch   700, epoch 0 : 0.210\n",
      "-----------------Total loss after mini-batch   800, epoch 0 : 0.190\n",
      "-----------------Total loss after mini-batch   900, epoch 0 : 0.245\n",
      "Evaluation----\n",
      "-----------------Total loss after epoch     0: 0.532\n",
      "-----------------Total loss after mini-batch  1000, epoch 1 : 0.218\n",
      "saved session to  ./models/mlp.pt\n",
      "-----------------Total loss after mini-batch  1100, epoch 1 : 0.224\n",
      "-----------------Total loss after mini-batch  1200, epoch 1 : 0.200\n",
      "-----------------Total loss after mini-batch  1300, epoch 1 : 0.197\n",
      "-----------------Total loss after mini-batch  1400, epoch 1 : 0.179\n",
      "-----------------Total loss after mini-batch  1500, epoch 1 : 0.211\n",
      "saved session to  ./models/mlp.pt\n",
      "-----------------Total loss after mini-batch  1600, epoch 1 : 0.221\n",
      "-----------------Total loss after mini-batch  1700, epoch 1 : 0.138\n",
      "-----------------Total loss after mini-batch  1800, epoch 1 : 0.272\n",
      "-----------------Total loss after mini-batch  1900, epoch 1 : 0.141\n",
      "-----------------Total loss after mini-batch  2000, epoch 2 : 0.204\n",
      "saved session to  ./models/mlp.pt\n",
      "-----------------Total loss after mini-batch  2100, epoch 2 : 0.220\n",
      "-----------------Total loss after mini-batch  2200, epoch 2 : 0.096\n",
      "-----------------Total loss after mini-batch  2300, epoch 2 : 0.122\n",
      "-----------------Total loss after mini-batch  2400, epoch 2 : 0.215\n",
      "-----------------Total loss after mini-batch  2500, epoch 2 : 0.145\n",
      "saved session to  ./models/mlp.pt\n",
      "-----------------Total loss after mini-batch  2600, epoch 2 : 0.110\n",
      "-----------------Total loss after mini-batch  2700, epoch 2 : 0.123\n",
      "-----------------Total loss after mini-batch  2800, epoch 2 : 0.137\n",
      "-----------------Total loss after mini-batch  2900, epoch 2 : 0.118\n",
      "-----------------Total loss after mini-batch  3000, epoch 3 : 0.170\n",
      "saved session to  ./models/mlp.pt\n",
      "-----------------Total loss after mini-batch  3100, epoch 3 : 0.118\n",
      "-----------------Total loss after mini-batch  3200, epoch 3 : 0.255\n",
      "-----------------Total loss after mini-batch  3300, epoch 3 : 0.162\n",
      "-----------------Total loss after mini-batch  3400, epoch 3 : 0.159\n",
      "-----------------Total loss after mini-batch  3500, epoch 3 : 0.137\n",
      "saved session to  ./models/mlp.pt\n",
      "-----------------Total loss after mini-batch  3600, epoch 3 : 0.220\n",
      "-----------------Total loss after mini-batch  3700, epoch 3 : 0.120\n",
      "-----------------Total loss after mini-batch  3800, epoch 3 : 0.143\n",
      "-----------------Total loss after mini-batch  3900, epoch 4 : 0.080\n",
      "-----------------Total loss after mini-batch  4000, epoch 4 : 0.132\n",
      "saved session to  ./models/mlp.pt\n",
      "-----------------Total loss after mini-batch  4100, epoch 4 : 0.179\n",
      "-----------------Total loss after mini-batch  4200, epoch 4 : 0.121\n",
      "-----------------Total loss after mini-batch  4300, epoch 4 : 0.221\n",
      "-----------------Total loss after mini-batch  4400, epoch 4 : 0.167\n",
      "-----------------Total loss after mini-batch  4500, epoch 4 : 0.144\n",
      "saved session to  ./models/mlp.pt\n",
      "-----------------Total loss after mini-batch  4600, epoch 4 : 0.114\n",
      "-----------------Total loss after mini-batch  4700, epoch 4 : 0.134\n",
      "-----------------Total loss after mini-batch  4800, epoch 4 : 0.111\n",
      "-----------------Total loss after mini-batch  4900, epoch 5 : 0.127\n",
      "-----------------Total loss after mini-batch  5000, epoch 5 : 0.093\n",
      "saved session to  ./models/mlp.pt\n",
      "-----------------Total loss after mini-batch  5100, epoch 5 : 0.141\n",
      "-----------------Total loss after mini-batch  5200, epoch 5 : 0.119\n",
      "-----------------Total loss after mini-batch  5300, epoch 5 : 0.072\n",
      "-----------------Total loss after mini-batch  5400, epoch 5 : 0.114\n",
      "-----------------Total loss after mini-batch  5500, epoch 5 : 0.158\n",
      "saved session to  ./models/mlp.pt\n",
      "-----------------Total loss after mini-batch  5600, epoch 5 : 0.150\n",
      "-----------------Total loss after mini-batch  5700, epoch 5 : 0.205\n",
      "-----------------Total loss after mini-batch  5800, epoch 5 : 0.164\n",
      "Evaluation----\n",
      "-----------------Total loss after epoch     5: 0.556\n",
      "-----------------Total loss after mini-batch  5900, epoch 6 : 0.089\n",
      "-----------------Total loss after mini-batch  6000, epoch 6 : 0.149\n",
      "saved session to  ./models/mlp.pt\n",
      "-----------------Total loss after mini-batch  6100, epoch 6 : 0.210\n",
      "-----------------Total loss after mini-batch  6200, epoch 6 : 0.221\n",
      "-----------------Total loss after mini-batch  6300, epoch 6 : 0.296\n",
      "-----------------Total loss after mini-batch  6400, epoch 6 : 0.148\n",
      "-----------------Total loss after mini-batch  6500, epoch 6 : 0.134\n",
      "saved session to  ./models/mlp.pt\n",
      "-----------------Total loss after mini-batch  6600, epoch 6 : 0.131\n",
      "-----------------Total loss after mini-batch  6700, epoch 6 : 0.134\n",
      "-----------------Total loss after mini-batch  6800, epoch 7 : 0.135\n",
      "-----------------Total loss after mini-batch  6900, epoch 7 : 0.196\n",
      "-----------------Total loss after mini-batch  7000, epoch 7 : 0.090\n",
      "saved session to  ./models/mlp.pt\n",
      "-----------------Total loss after mini-batch  7100, epoch 7 : 0.199\n",
      "-----------------Total loss after mini-batch  7200, epoch 7 : 0.071\n",
      "-----------------Total loss after mini-batch  7300, epoch 7 : 0.173\n",
      "-----------------Total loss after mini-batch  7400, epoch 7 : 0.119\n",
      "-----------------Total loss after mini-batch  7500, epoch 7 : 0.147\n",
      "saved session to  ./models/mlp.pt\n",
      "-----------------Total loss after mini-batch  7600, epoch 7 : 0.109\n",
      "-----------------Total loss after mini-batch  7700, epoch 7 : 0.216\n",
      "-----------------Total loss after mini-batch  7800, epoch 8 : 0.111\n",
      "-----------------Total loss after mini-batch  7900, epoch 8 : 0.130\n",
      "-----------------Total loss after mini-batch  8000, epoch 8 : 0.119\n",
      "saved session to  ./models/mlp.pt\n",
      "-----------------Total loss after mini-batch  8100, epoch 8 : 0.154\n",
      "-----------------Total loss after mini-batch  8200, epoch 8 : 0.186\n",
      "-----------------Total loss after mini-batch  8300, epoch 8 : 0.092\n",
      "-----------------Total loss after mini-batch  8400, epoch 8 : 0.114\n",
      "-----------------Total loss after mini-batch  8500, epoch 8 : 0.058\n",
      "saved session to  ./models/mlp.pt\n",
      "-----------------Total loss after mini-batch  8600, epoch 8 : 0.146\n",
      "-----------------Total loss after mini-batch  8700, epoch 8 : 0.151\n",
      "-----------------Total loss after mini-batch  8800, epoch 9 : 0.111\n",
      "-----------------Total loss after mini-batch  8900, epoch 9 : 0.151\n",
      "-----------------Total loss after mini-batch  9000, epoch 9 : 0.136\n",
      "saved session to  ./models/mlp.pt\n",
      "-----------------Total loss after mini-batch  9100, epoch 9 : 0.160\n",
      "-----------------Total loss after mini-batch  9200, epoch 9 : 0.053\n",
      "-----------------Total loss after mini-batch  9300, epoch 9 : 0.128\n",
      "-----------------Total loss after mini-batch  9400, epoch 9 : 0.132\n",
      "-----------------Total loss after mini-batch  9500, epoch 9 : 0.095\n",
      "saved session to  ./models/mlp.pt\n",
      "-----------------Total loss after mini-batch  9600, epoch 9 : 0.133\n"
     ]
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "# Run the training loop\n",
    "i = 0\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for data in train_dataloader:\n",
    "        # Get batch of data\n",
    "        inputs, labels = data\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Perform forward pass\n",
    "        network_output = model.forward(inputs)\n",
    "        # Compute loss\n",
    "        loss = criterion(network_output, labels)\n",
    "        # Ensure no funny numerics\n",
    "        assert not torch.isnan(loss).any()\n",
    "        # Perform backward pass\n",
    "        loss.backward()\n",
    "        # \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 10.0)\n",
    "        # Perform optimization\n",
    "        optimizer.step()\n",
    "        # Print statistics\n",
    "        current_loss = loss.item()\n",
    "        if i % 100 == 0:\n",
    "            print('-----------------Total loss after mini-batch %5d, epoch %d : %.3f' % (i, epoch, current_loss))\n",
    "            current_loss = 0.0\n",
    "        if i % 500 == 0:\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            print(\"saved session to \", model_save_path)\n",
    "\n",
    "        i+=1\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        # eval\n",
    "        model.eval()\n",
    "        total_loss = 0\n",
    "\n",
    "        for data in eval_dataloader:\n",
    "            # Get batch of data\n",
    "            inputs, labels = data\n",
    "            # Perform forward pass\n",
    "            network_output = model.forward(inputs)\n",
    "            # Compute loss\n",
    "            loss = criterion(network_output, labels)\n",
    "            total_loss += loss.detach().item()\n",
    "\n",
    "        print(\"Evaluation----\")\n",
    "        print('-----------------Total loss after epoch %5d: %.3f' % (epoch, total_loss / len(eval_dataloader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08ccbaf",
   "metadata": {},
   "source": [
    "## Visualize the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fc27758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPModel(\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=104, out_features=512, bias=True)\n",
       "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (7): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU()\n",
       "    (9): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (10): ReLU()\n",
       "    (11): Linear(in_features=64, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = network_cls()\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "model.to(DEVICE)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "957a084a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: only try validation set\n",
    "idx = np.random.randint(len(RAW_DATA))\n",
    "current_pos, goal_pos, occ_grid, next_pos, _, _ = RAW_DATA[idx]\n",
    "predicted_pos = model.forward(dataset[idx][0].view(1, -1)).detach().cpu().numpy().flatten()\n",
    "visualize_data(occ_grid, current_pos, goal_pos, next_pos, predicted_pos=predicted_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562d898a",
   "metadata": {},
   "source": [
    "# Motion planning test\n",
    "\n",
    "Test dataset (100 sets):\n",
    "- Obstacles\n",
    "- Start\n",
    "- Goal\n",
    "- Path of astar\n",
    "\n",
    "Evaluation metric:\n",
    "- Sucess: close to the goal within a tolerance, path not in collision\n",
    "- Path length: "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b1513172bc75592431e687543e7a7e71518769f9e336f9ec823ad71ba40cd915"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('wbmp': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
