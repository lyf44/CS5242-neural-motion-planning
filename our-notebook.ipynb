{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4ef79b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f313fd07",
   "metadata": {},
   "source": [
    "# Data generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaa7faa",
   "metadata": {},
   "source": [
    "## Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8dd910d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9e6349",
   "metadata": {},
   "source": [
    "## Save generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8bc314c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c44b554",
   "metadata": {},
   "source": [
    "# Visualization of the generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "523965c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "DATA_FILE_PATH_TO_LOAD = './dataset/data_3_g.json'\n",
    "RAW_DATA = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db083bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_data(occ_g, current_pos, goal_pos, next_pos, predicted_pos=None):\n",
    "    occ_g = np.array(occ_g).reshape(10, 10)\n",
    "    fig, ax = plt.subplots(1, figsize=(10, 10), dpi=100)\n",
    "    occ_grid_size = occ_g.shape[0]\n",
    "    tmp = occ_grid_size / 4.0 - 0.25\n",
    "    s = (10.0 / occ_grid_size * 100 / 2) ** 2 + 500\n",
    "    for i in range(occ_grid_size):\n",
    "        for j in range(occ_grid_size):\n",
    "            if occ_g[i,j] == 1:\n",
    "                plt.scatter(j/2.0 - tmp, tmp - i/2.0, color=\"black\", marker='s', s=s, alpha=1) # init\n",
    "\n",
    "    ax.add_patch(patches.Rectangle((current_pos[0]-0.1, current_pos[1]-0.1), 0.2, 0.2, facecolor='y'))\n",
    "    ax.add_patch(patches.Rectangle((goal_pos[0]-0.1, goal_pos[1]-0.1), 0.2, 0.2, facecolor='r'))\n",
    "    ax.add_patch(patches.Rectangle((next_pos[0]-0.09, next_pos[1]-0.09), 0.18, 0.18, facecolor='g'))\n",
    "    if predicted_pos is not None:\n",
    "        ax.add_patch(patches.Rectangle((predicted_pos[0]-0.09, predicted_pos[1]-0.09), 0.18, 0.18, facecolor='b'))\n",
    "\n",
    "                \n",
    "    ax.set_title(\"Visualization\")\n",
    "    ax.set_xlim(-2.5,2.5)\n",
    "    ax.set_ylim(-2.5,2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba77f9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RAW_DATA is None:\n",
    "    with open(DATA_FILE_PATH_TO_LOAD) as _file:\n",
    "        RAW_DATA = json.load(_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e90dc01",
   "metadata": {},
   "source": [
    "Randomly visualze a single data point.\n",
    "\n",
    "- Black: obstacles\n",
    "- Red: goal position\n",
    "- Yellow: current position\n",
    "- Green: the next position the robot should take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "502e2fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = np.random.randint(len(RAW_DATA))\n",
    "current_pos, goal_pos, occ_grid, next_pos, _, _ = RAW_DATA[idx]\n",
    "visualize_data(occ_grid, current_pos, goal_pos, next_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d73f4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0a7a066",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7980230b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fbda5a",
   "metadata": {},
   "source": [
    "## Definitions of networks and dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e9aeb8",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cee5e1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPDataset(Dataset):\n",
    "    \"\"\"A dataset class for the MLP.\n",
    "    \n",
    "    Input: A vector that concat current position, goal position and occupancy grid vector\n",
    "    Output: Next position\n",
    "    \"\"\"\n",
    "    def __init__(self, raw_data, transform=None, target_transform=None, device=\"cpu\"):\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.device = device\n",
    "        self.dataset = raw_data\n",
    "        print(\"dataset size = {}\".format(len(self.dataset)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start_pos, goal_pos, occ_grid, next_pos, non_connectable_nodes, dist = self.dataset[idx]\n",
    "\n",
    "        dim = len(start_pos)\n",
    "        start_pos = torch.Tensor(start_pos)\n",
    "        goal_pos = torch.Tensor(goal_pos)\n",
    "        occ_grid = torch.Tensor(occ_grid)\n",
    "        next_pos = torch.Tensor(next_pos)\n",
    "\n",
    "        input = torch.cat((start_pos, goal_pos, occ_grid), dim=0).to(self.device)\n",
    "        next_pos = next_pos.to(self.device)\n",
    "\n",
    "        return input, next_pos\n",
    "\n",
    "    @classmethod\n",
    "    def load_dataset_from_file(cls, file_path, device='cpu'):\n",
    "        print(\"Loading data from {}\".format(file_path))\n",
    "        with open(file_path, 'r') as f:\n",
    "            dataset = json.load(f)\n",
    "        return cls(dataset, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9227eae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPModel(nn.Module):\n",
    "    \"\"\"A trivially simple MLP model.\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(104, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return self.layers(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0ca71e",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135cb441",
   "metadata": {},
   "source": [
    "Choose the network and dataloader classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8387e74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_cls = MLPDataset\n",
    "network_cls = MLPModel\n",
    "criterion = torch.nn.MSELoss()\n",
    "model_save_path = './models/mlp.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191edde8",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74b1772f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size = 68957\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset_cls(RAW_DATA, device=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a616f6b",
   "metadata": {},
   "source": [
    "Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b8fa944",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPModel().to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdadb072",
   "metadata": {},
   "source": [
    "Run the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b46440e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(dataset) * 0.9)\n",
    "batch_size = 64\n",
    "learning_rate = 1e-4\n",
    "num_epochs=10\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b46dae64",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torch.utils.data.Subset(dataset, np.arange(train_size))\n",
    "val_set = torch.utils.data.Subset(dataset, np.arange(train_size, len(dataset)))\n",
    "train_dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "eval_dataloader = DataLoader(val_set, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93ac2dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------Total loss after mini-batch     0, epoch 0 : 1.511\n",
      "saved session to  ./models/mlp.pt\n",
      "-----------------Total loss after mini-batch   100, epoch 0 : 0.264\n",
      "-----------------Total loss after mini-batch   200, epoch 0 : 0.332\n",
      "-----------------Total loss after mini-batch   300, epoch 0 : 0.259\n",
      "-----------------Total loss after mini-batch   400, epoch 0 : 0.364\n",
      "-----------------Total loss after mini-batch   500, epoch 0 : 0.418\n",
      "saved session to  ./models/mlp.pt\n",
      "-----------------Total loss after mini-batch   600, epoch 0 : 0.262\n",
      "-----------------Total loss after mini-batch   700, epoch 0 : 0.210\n",
      "-----------------Total loss after mini-batch   800, epoch 0 : 0.190\n",
      "-----------------Total loss after mini-batch   900, epoch 0 : 0.245\n",
      "Evaluation----\n",
      "-----------------Total loss after epoch     0: 0.532\n",
      "-----------------Total loss after mini-batch  1000, epoch 1 : 0.218\n",
      "saved session to  ./models/mlp.pt\n",
      "-----------------Total loss after mini-batch  1100, epoch 1 : 0.224\n",
      "-----------------Total loss after mini-batch  1200, epoch 1 : 0.200\n",
      "-----------------Total loss after mini-batch  1300, epoch 1 : 0.197\n",
      "-----------------Total loss after mini-batch  1400, epoch 1 : 0.179\n",
      "-----------------Total loss after mini-batch  1500, epoch 1 : 0.211\n",
      "saved session to  ./models/mlp.pt\n",
      "-----------------Total loss after mini-batch  1600, epoch 1 : 0.221\n",
      "-----------------Total loss after mini-batch  1700, epoch 1 : 0.138\n",
      "-----------------Total loss after mini-batch  1800, epoch 1 : 0.272\n",
      "-----------------Total loss after mini-batch  1900, epoch 1 : 0.141\n",
      "-----------------Total loss after mini-batch  2000, epoch 2 : 0.204\n",
      "saved session to  ./models/mlp.pt\n",
      "-----------------Total loss after mini-batch  2100, epoch 2 : 0.220\n",
      "-----------------Total loss after mini-batch  2200, epoch 2 : 0.096\n",
      "-----------------Total loss after mini-batch  2300, epoch 2 : 0.122\n",
      "-----------------Total loss after mini-batch  2400, epoch 2 : 0.215\n",
      "-----------------Total loss after mini-batch  2500, epoch 2 : 0.145\n",
      "saved session to  ./models/mlp.pt\n",
      "-----------------Total loss after mini-batch  2600, epoch 2 : 0.110\n",
      "-----------------Total loss after mini-batch  2700, epoch 2 : 0.123\n",
      "-----------------Total loss after mini-batch  2800, epoch 2 : 0.137\n",
      "-----------------Total loss after mini-batch  2900, epoch 2 : 0.118\n",
      "-----------------Total loss after mini-batch  3000, epoch 3 : 0.170\n",
      "saved session to  ./models/mlp.pt\n",
      "-----------------Total loss after mini-batch  3100, epoch 3 : 0.118\n",
      "-----------------Total loss after mini-batch  3200, epoch 3 : 0.255\n",
      "-----------------Total loss after mini-batch  3300, epoch 3 : 0.162\n",
      "-----------------Total loss after mini-batch  3400, epoch 3 : 0.159\n",
      "-----------------Total loss after mini-batch  3500, epoch 3 : 0.137\n",
      "saved session to  ./models/mlp.pt\n",
      "-----------------Total loss after mini-batch  3600, epoch 3 : 0.220\n",
      "-----------------Total loss after mini-batch  3700, epoch 3 : 0.120\n",
      "-----------------Total loss after mini-batch  3800, epoch 3 : 0.143\n",
      "-----------------Total loss after mini-batch  3900, epoch 4 : 0.080\n",
      "-----------------Total loss after mini-batch  4000, epoch 4 : 0.132\n",
      "saved session to  ./models/mlp.pt\n",
      "-----------------Total loss after mini-batch  4100, epoch 4 : 0.179\n",
      "-----------------Total loss after mini-batch  4200, epoch 4 : 0.121\n",
      "-----------------Total loss after mini-batch  4300, epoch 4 : 0.221\n",
      "-----------------Total loss after mini-batch  4400, epoch 4 : 0.167\n",
      "-----------------Total loss after mini-batch  4500, epoch 4 : 0.144\n",
      "saved session to  ./models/mlp.pt\n",
      "-----------------Total loss after mini-batch  4600, epoch 4 : 0.114\n",
      "-----------------Total loss after mini-batch  4700, epoch 4 : 0.134\n",
      "-----------------Total loss after mini-batch  4800, epoch 4 : 0.111\n",
      "-----------------Total loss after mini-batch  4900, epoch 5 : 0.127\n",
      "-----------------Total loss after mini-batch  5000, epoch 5 : 0.093\n",
      "saved session to  ./models/mlp.pt\n",
      "-----------------Total loss after mini-batch  5100, epoch 5 : 0.141\n",
      "-----------------Total loss after mini-batch  5200, epoch 5 : 0.119\n",
      "-----------------Total loss after mini-batch  5300, epoch 5 : 0.072\n",
      "-----------------Total loss after mini-batch  5400, epoch 5 : 0.114\n",
      "-----------------Total loss after mini-batch  5500, epoch 5 : 0.158\n",
      "saved session to  ./models/mlp.pt\n",
      "-----------------Total loss after mini-batch  5600, epoch 5 : 0.150\n",
      "-----------------Total loss after mini-batch  5700, epoch 5 : 0.205\n",
      "-----------------Total loss after mini-batch  5800, epoch 5 : 0.164\n",
      "Evaluation----\n",
      "-----------------Total loss after epoch     5: 0.556\n",
      "-----------------Total loss after mini-batch  5900, epoch 6 : 0.089\n",
      "-----------------Total loss after mini-batch  6000, epoch 6 : 0.149\n",
      "saved session to  ./models/mlp.pt\n",
      "-----------------Total loss after mini-batch  6100, epoch 6 : 0.210\n",
      "-----------------Total loss after mini-batch  6200, epoch 6 : 0.221\n",
      "-----------------Total loss after mini-batch  6300, epoch 6 : 0.296\n",
      "-----------------Total loss after mini-batch  6400, epoch 6 : 0.148\n",
      "-----------------Total loss after mini-batch  6500, epoch 6 : 0.134\n",
      "saved session to  ./models/mlp.pt\n",
      "-----------------Total loss after mini-batch  6600, epoch 6 : 0.131\n",
      "-----------------Total loss after mini-batch  6700, epoch 6 : 0.134\n",
      "-----------------Total loss after mini-batch  6800, epoch 7 : 0.135\n",
      "-----------------Total loss after mini-batch  6900, epoch 7 : 0.196\n",
      "-----------------Total loss after mini-batch  7000, epoch 7 : 0.090\n",
      "saved session to  ./models/mlp.pt\n",
      "-----------------Total loss after mini-batch  7100, epoch 7 : 0.199\n",
      "-----------------Total loss after mini-batch  7200, epoch 7 : 0.071\n",
      "-----------------Total loss after mini-batch  7300, epoch 7 : 0.173\n",
      "-----------------Total loss after mini-batch  7400, epoch 7 : 0.119\n",
      "-----------------Total loss after mini-batch  7500, epoch 7 : 0.147\n",
      "saved session to  ./models/mlp.pt\n",
      "-----------------Total loss after mini-batch  7600, epoch 7 : 0.109\n",
      "-----------------Total loss after mini-batch  7700, epoch 7 : 0.216\n",
      "-----------------Total loss after mini-batch  7800, epoch 8 : 0.111\n",
      "-----------------Total loss after mini-batch  7900, epoch 8 : 0.130\n",
      "-----------------Total loss after mini-batch  8000, epoch 8 : 0.119\n",
      "saved session to  ./models/mlp.pt\n",
      "-----------------Total loss after mini-batch  8100, epoch 8 : 0.154\n",
      "-----------------Total loss after mini-batch  8200, epoch 8 : 0.186\n",
      "-----------------Total loss after mini-batch  8300, epoch 8 : 0.092\n",
      "-----------------Total loss after mini-batch  8400, epoch 8 : 0.114\n",
      "-----------------Total loss after mini-batch  8500, epoch 8 : 0.058\n",
      "saved session to  ./models/mlp.pt\n",
      "-----------------Total loss after mini-batch  8600, epoch 8 : 0.146\n",
      "-----------------Total loss after mini-batch  8700, epoch 8 : 0.151\n",
      "-----------------Total loss after mini-batch  8800, epoch 9 : 0.111\n",
      "-----------------Total loss after mini-batch  8900, epoch 9 : 0.151\n",
      "-----------------Total loss after mini-batch  9000, epoch 9 : 0.136\n",
      "saved session to  ./models/mlp.pt\n",
      "-----------------Total loss after mini-batch  9100, epoch 9 : 0.160\n",
      "-----------------Total loss after mini-batch  9200, epoch 9 : 0.053\n",
      "-----------------Total loss after mini-batch  9300, epoch 9 : 0.128\n",
      "-----------------Total loss after mini-batch  9400, epoch 9 : 0.132\n",
      "-----------------Total loss after mini-batch  9500, epoch 9 : 0.095\n",
      "saved session to  ./models/mlp.pt\n",
      "-----------------Total loss after mini-batch  9600, epoch 9 : 0.133\n"
     ]
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "# Run the training loop\n",
    "i = 0\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for data in train_dataloader:\n",
    "        # Get batch of data\n",
    "        inputs, labels = data\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Perform forward pass\n",
    "        network_output = model.forward(inputs)\n",
    "        # Compute loss\n",
    "        loss = criterion(network_output, labels)\n",
    "        # Ensure no funny numerics\n",
    "        assert not torch.isnan(loss).any()\n",
    "        # Perform backward pass\n",
    "        loss.backward()\n",
    "        # \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 10.0)\n",
    "        # Perform optimization\n",
    "        optimizer.step()\n",
    "        # Print statistics\n",
    "        current_loss = loss.item()\n",
    "        if i % 100 == 0:\n",
    "            print('-----------------Total loss after mini-batch %5d, epoch %d : %.3f' % (i, epoch, current_loss))\n",
    "            current_loss = 0.0\n",
    "        if i % 500 == 0:\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            print(\"saved session to \", model_save_path)\n",
    "\n",
    "        i+=1\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        # eval\n",
    "        model.eval()\n",
    "        total_loss = 0\n",
    "\n",
    "        for data in eval_dataloader:\n",
    "            # Get batch of data\n",
    "            inputs, labels = data\n",
    "            # Perform forward pass\n",
    "            network_output = model.forward(inputs)\n",
    "            # Compute loss\n",
    "            loss = criterion(network_output, labels)\n",
    "            total_loss += loss.detach().item()\n",
    "\n",
    "        print(\"Evaluation----\")\n",
    "        print('-----------------Total loss after epoch %5d: %.3f' % (epoch, total_loss / len(eval_dataloader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08ccbaf",
   "metadata": {},
   "source": [
    "## Visualize the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fc27758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPModel(\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=104, out_features=512, bias=True)\n",
       "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (7): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU()\n",
       "    (9): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (10): ReLU()\n",
       "    (11): Linear(in_features=64, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = network_cls()\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "model.to(DEVICE)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "957a084a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzkAAAM1CAYAAABT0D9iAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAhoUlEQVR4nO3de6ykd33f8c8XFhZqjg0sN4Gz4eI1LiCETIIgbcGIQGmFBKQhECctplK4hJCSFtJaVCXQNPAPFil2LqWArcoiidtAoG2ApPFCBOFmCioKYRfbYAyxMUux18UsEfz6x8xpjw97O8c785z9zusljY7nOTPzfM/68Xrf+3vmmRpjBAAAoIu7TT0AAADAqSRyAACAVkQOAADQisgBAABaETkAAEArIgcAAGhF5AAAAK2IHAAAoBWRAwAAtCJyAFZcVV1UVaOqHr7T5qiq/VW1f4JZJtkvAKeGyAFoqKreV1Xfqaq14zzmyqr6XpI9Sxxtx6iqx1TVr00ddwCceiIHoKcrk9w7yfOP9s2q+ltJnpvkA0neOn/sV5Y13BY8a35bhMckeX2Shy95vwAsmMgB6Ol9SQ4nufAY339ukjOSXDnG+P4Y47tjjLG06U7SGON7Y4zvrcp+ATg1RA5AQ2OMO5L8YZJnVNWDjvKQCzOLoPcd470wP1ZVH6yqb1bVHVV1fVW9c8P3L5g/54KNL1pVD59vv2jDtsdX1eVVdV1Vfbeqbqqqd1bVCU+T2/zemKr68vz1j3a7YP6YH62q36qqL85nP1RVV236+S5KctX87tVHeY0fek9OVT2oqt5RVTfPf47PVdWLj/Hzv6aqXlpV11bVkar6VFX9+Il+XgBOjV1TDwDAwlyZ5MVJfibJpesbq+r+Sf5+knePMe6oqjs9aR5FH0pyS5I3J/l2Zqd0/dQ253hmkkcmeVeSm5I8NslLkzy2qp68xRWkVye5z6Ztv5LkCUkOze//eJKfSPJ7SW7MbPZXJNlfVY8ZY3wnyUeS/Pskv5zkN5J8Yf7cL+QoqureSfYnOSezX8vrk7wgyeVVdd8xxm9uesqFSdaS/G6SkeRXk/xhVT1yjPE3W/h5AdgGkQPQ158l+evM/sB96YbtL0hyj8wi6Gh+Isn9kjxrjPHpDdv/9Tbn+K0xxls2bqiqjyd5d5K/m+TPT/aFxhjv3fQ6L0hyfpJ/M8b4X/PN/22M8Z83Pe79Sf4iyT9K8p/GGNdV1Z9nFjl/MsbYf4JdvzTJ307y82OMK+ev+TtJPpzk16vqnWOMwxsevzfJvjHG/54/9otJ/iizuPyvJ/vzArA9TlcDaGqM8f3MVjOesukKYhcmuTnJ/zjGU789//qcqrrHKZjjjvV/rqp7VdUDknx8vun87b5uVT0myTszi4dfP8b+7jE/Le5Lmf1c293fP8xsFerdG/bzN5mtBt0nydM2Pf731wNnbj3kHrnN/QOwBSIHoLf11ZoLk6Sqzk7y95L83jyCjubDSf5LZlce+2ZV/VFVvaSqdm9ngKq6f1X9ZlXdnOSOzE6Du37+7bO2+ZpnZvaeo68l+ScbT3mrqntX1Rur6qtJjiT55nyf993u/pL8aJKDY4wfbNr+hQ3f3+iGjXc2BM/9trl/ALZA5AA0Nsa4JslfJfnZ+aafTVI59qlqGTM/neQpmZ3m9rDMVkyuqar198Mc6300dz/Ktj9I8gtJfiez9/U8K8mz59/b7v+HLk/y0CTPG2Pctul7b0vyuvl+f2a+v2dm9p6dZf1/71gBWcfYDsAp5D05AP1dmeTfVtXjM1vROTjG+NSJnjTG+Hhmp5W9rqounL/Oi5L8xyTrKxP33fS0O61oVNX9kjwjyevHGG/csH3f9n6UpKr+VZLnJfmpMcZfHeUhP53kijHGv9jwnHsdZdatXPDgK0keX1V327Sac96G7wOwQ1jJAehvfdXmjZldheyYqzjJLExq8yXXks/Ov66fsvaVzFYrnrrpcb+46f76isbm13v18WY4zmw/mdn7b/7d5osQbNrn5v29Kj+8yvR/5l/vexK7/u9JHpLkhRtm2TV/3dszO8UPgB3CSg5Ac2OM66vqY5l9AGhygsjJ7LLTv1hV70lybWaXQv6FJLdl9of9jDFuraqrkryqqsb8cc9JcqfP5Blj3FZVH0nyq/OLGHwts9PHHrHNH+fdmb2/5mBV/fym7/3JGOPmzK5e9o+r6tYkf5nZaXc/mf9/iel1n80siP5lVZ2V2ft3/myM8Y2j7Pc/JHlZZpeMfmKSL2e2YvR3krx605XVAJiYyAFYDVdmdmnoT44xvnSCx344yZMyOzXtwUluTfLJJD83xrh+w+NeldmlqF+eWSD8QZLXJvn8pte7MLP3ybwysxWWDyX5B0m+vo2f4wHzr1cc5XtPz+yqcf8ss3j5uST3SvLRzCLngxsfPMa4qapenuTiJO/IbKXn6Ul+KHLmnyd0QWafG/TiJGcm+WKSl4wxLt/GzwHAAtXWPoMNAABgZ/OeHAAAoBWRAwAAtCJyAACAVkQOAADQisgBAABaETkAAEArO/pzcuafuP3QJD5kDQAAWEvy9XGCz8HZ0ZGTWeDcOPUQAADAjnF2kq8d7wE7PXIOJ8lXv/rVnHnmmVPPAgAATOS2227Lj/zIjyQncZbXTo+cJMmZZ54pcgAAgJPiwgMAAEArIgcAAGhF5AAAAK2IHAAAoBWRAwAAtCJyAACAVkQOAADQisgBAABaETkAAEArIgcAAGhF5AAAAK2IHAAAoBWRAwAAtCJyAACAVkQOAADQisgBAABaETkAAEArIgcAAGhF5AAAAK2IHAAAoBWRAwAAtCJyAACAVkQOAADQisgBAABaETkAAEArIgcAAGhF5AAAAK2IHAAAoBWRAwAAtCJyAACAVkQOAADQisgBAABaETkAAEArIgcAAGhF5AAAAK2IHAAAoBWRAwAAtCJyAACAVkQOAADQisgBAABaETkAAEArIgcAAGhF5AAAAK2IHAAAoBWRAwAAtCJyAACAVkQOAADQisgBAABaETkAAEArIgcAAGhF5AAAAK2IHAAAoBWRAwAAtCJyAACAVkQOAADQisgBAABaETkAAEArIgcAAGhF5AAAAK2IHAAAoBWRAwAAtCJyAACAVkQOAADQisgBAABaETkAAEArIgcAAGhF5AAAAK2IHAAAoJWFRk5VXVxVn6qqw1X1jap6b1U9epH7BAAAVtuiV3KeluSyJE9O8swk90jyoao6Y8H7BQAAVtSuRb74GOPZG+9X1UVJvpHkiUk+ssh9AwAAq2nZ78k5a/71W0veLwAAsCIWupKzUVXdLclbk3x0jPH5Yzxmd5LdGzatLWE0AACgkWWu5FyW5HFJXnScx1yc5NYNtxuXMBcAANDIUiKnqi5N8pwkTx9jHC9c3pTZKW3rt7OXMB4AANDIQk9Xq6pK8rYkz09ywRjj+uM9foxxJMmRDc9f5HgAAEBDi35PzmVJLkzy3CSHq+oh8+23jjHuWPC+AQCAFbTo09VekdlpZ/uT/PWG2wsXvF8AAGBFLfpzcpxvBgAALNWyPycHAABgoUQOAADQisgBAABaETkAAEArIgcAAGhF5AAAAK2IHAAAoBWRAwAAtCJyAACAVkQOAADQisgBAABaETkAAEArIgcAAGhF5AAAAK2IHAAAoBWRAwAAtCJyAACAVkQOAADQisgBAABaETkAAEArIgcAAGhF5AAAAK2IHAAAoBWRAwAAtCJyAACAVkQOAADQisgBAABaETkAAEArIgcAAGhF5AAAAK2IHAAAoBWRAwAAtCJyAACAVkQOAADQisgBAABaETkAAEArIgcAAGhF5AAAAK2IHAAAoBWRAwAAtCJyAACAVkQOAADQisgBAABaETkAAEArIgcAAGhF5AAAAK2IHAAAoBWRAwAAtCJyAACAVkQOAADQisgBAABaETkAAEArIgcAAGhF5AAAAK2IHAAAoBWRAwAAtCJyAACAVkQOAADQisgBAABaETkAAEArIgcAAGhF5AAAAK2IHAAAoBWRAwAAtCJyAACAVkQOAADQisgBAABaETkAAEAru6Ye4GRce+21GWNMPcZpY21tLUly+PDhiSc5faytrWXfvn1TjwEAwClwWkTO+eefP/UIrIADBw4IHQCABpyuBnNWvgAAehA5AABAKyIHAABoReQAAACtiBwAAKAVkQMAALQicgAAgFZEDgAA0IrIAQAAWhE5AABAKyIHAABoReQAAACtiBwAAKAVkQMAALQicgAAgFZEDgAA0IrIAQAAWhE5AABAKyIHAABoReQAAACtiBwAAKAVkQMAALQicgAAgFZEDgAA0IrIAQAAWhE5AABAKyIHAABoReQAAACtiBwAAKAVkQMAALQicgAAgFZEDgAA0IrIAQAAWhE5AABAKyIHAABoReQAAACtiBwAAKAVkQMAALQicgAAgFZEDgAA0IrIAQAAWhE5AABAKyIHAABoReQAAACtiBwAAKAVkQMAALQicgAAgFZEDgAA0IrIAQAAWhE5AABAKyIHAABoReQAAACtiBwAAKAVkQMAALQicgAAgFZEDgAA0IrIAQAAWhE5AABAKyIHAABoReQAAACtiBwAAKAVkQMAALQicgAAgFZEDgAA0IrIAQAAWhE5AABAKyIHAABoReQAAACtiBwAAKAVkQMAALSy0MipqqdW1fur6utVNarqeYvcHwAAwKJXcs5I8rkkr1zwfgAAAJIkuxb54mOMP07yx0lSVYvcFQAAQBLvyQEAAJpZ6ErOVlXV7iS7N2xam2oWAADg9LTTVnIuTnLrhtuN047DKjl06NDUIwAAcArstMh5U5KzNtzOnnYcVsmePXumHgEAgFNgR52uNsY4kuTI+n0XKwAAALZqoZFTVfdJcs6GTY+oqick+dYY44ZF7hsAAFhNi17J+bEkV2+4f8n86xVJLlrwvgEAgBW06M/J2Z/EOWcAAMDS7LQLDwAAANwlIgcAAGhF5AAAAK2IHAAAoBWRAwAAtCJyAACAVkQOAADQisgBAABaETkAAEArIgcAAGhF5AAAAK2IHAAAoBWRAwAAtCJyAACAVkQOAADQisgBAABaETkAAEArIgcAAGhF5AAAAK2IHAAAoBWRAwAAtCJyAACAVnZNPQAAdFe13P2Nsdz9Aew0VnIAAIBWRA4AANCKyAEAAFoROQAAQCsiBwAAaEXkAAAArYgcAACgFZEDAAC0InIAAIBWdk09AAAAPezfX5Pt+4ILxmT7ZuexkgMAALQicgAAgFZEDgAA0IrIAQAAWhE5AABAK66uBgCnWL1h8xWmXPUJYJms5AAAAK2IHAAAoBWRAwAAtCJyAACAVkQOAADQisgBAABaETkAAEArIgcAAGhF5AAAAK2IHAAAoJVdUw8AAO39Wi305cfrx0JfH+B0YyUHAABoReQAAACtiBwAAKAVkQMAALQicgAAgFZEDgAA0IrIAQAAWhE5AABAKyIHAABoReQAAACtiBwAAKAVkQMAALQicgAAgFZ2TT0AAAA9XHDBmHoESGIlBwAAaMZKDgCcYuP1/jYbYEpWcgAAgFZEDgAA0IrT1QCgsYMHD+bw4cNTj3HaWFtbSxK/ZluwtraWffv2TT0G3InIAYCmDh48mHPPPXfqMVgBBw4cEDrsKE5Xg7n1v70D6MJqBMviWGOnOS1Wcj7zmc9kDFeqOVmW2rfOUjsAQB+nReQ86lGPyplnnjn1GAAAwGnA6WoAAEArIgcAAGhF5AAAAK2IHAAAoBWRAwAAtCJyAACAVkQOAADQisgBAABaETkAAEArIgcAAGhF5AAAAK2IHAAAoBWRAwAAtCJyAACAVkQOAADQisgBAABaETkAAEArIgcAAGhF5AAAAK2IHAAAoBWRAwAAtCJyAACAVkQOAADQisgBAABaETkAAEArIgcAAGhF5AAAAK2IHAAAoBWRAwAAtCJyAACAVkQOAADQisgBAABaETkAAEArIgcAAGhF5AAAAK2IHAAAoBWRAwAAtCJyAACAVkQOAADQisgBAABaETkAAEArIgcAAGhF5AAAAK2IHAAAoBWRAwAAtCJyAACAVkQOAADQisgBAABaETkAAEArIgcAAGhF5AAAAK2IHAAAoBWRAwAAtCJyAACAVkQOAADQisgBAABaETkAAEArIgcAAGhF5AAAAK2IHAAAoBWRAwAAtCJyAACAVkQOAADQisgBAABaETkAAEArIgcAAGhF5AAAAK0sJXKq6pVV9eWq+m5VfaKqnrSM/QIAAKtn4ZFTVS9MckmSNyQ5P8nnknywqh606H0DAACrZxkrOf88ydvHGO8aY/xlkpcn+U6Sf7qEfQMAACtmoZFTVfdM8sQkf7q+bYzxg/n9pyxy3wAAwGrateDXf0CSuye5edP2m5Oct/nBVbU7ye4Nm9YWNxoAANDRTru62sVJbt1wu3HacQDg9HXo0KGpR2BFONbYaRYdOd9M8v0kD960/cFJbjrK49+U5KwNt7MXOh0ANLZnz56pR2BFONbYaRYaOWOM7yW5Jskz1rdV1d3m9//iKI8/Msa4bf2W5PAi5wMAAPpZ9Htyktnlo6+oqk8n+WSSVyc5I8m7lrBvAABgxSw8csYYv19VD0zyxiQPSfLZJM8eY2y+GAEAAMBdtoyVnIwxLk1y6TL2BQAArLaddnU1AACAu0TkAAAArYgcAACgFZEDAAC0InIAAIBWRA4AANCKyAEAAFoROQAAQCsiBwAAaEXkAAAArYgcAACgFZEDAAC0InIAAIBWRA4AANCKyAEAAFoROQAAQCsiBwAAaEXkAAAArYgcAACgFZEDAAC0InIAAIBWRA4AANCKyAEAAFoROQAAQCsiBwAAaEXkAAAArYgcAACgFZEDAAC0InIAAIBWRA4AANCKyAEAAFoROQAAQCsiBwAAaEXkAAAArYgcAACgFZEDAAC0InIAAIBWRA4AANCKyAEAAFoROQAAQCsiBwAAaEXkAAAArYgcAACgFZEDAAC0InIAAIBWRA4AANCKyAEAAFoROQAAQCsiBwAAaEXkAAAArYgcAACgFZEDAAC0InIAAIBWRA4AANCKyAEAAFoROQAAQCsiBwAAaEXkAAAArYgcAACgFZEDAAC0InIAAIBWRA4AANCKyAEAAFoROQAAQCsiBwAAaEXkAAAArYgcAACgFZEDAAC0InIAAIBWRA4ANHXDDTdMPQIrwrHGTiNyAACAVkQOADS1d+/eqUdgRTjW2GlEDgAA0IrIAQAAWhE5AABAKyIHAABoReQAAACtiBwAAKAVkQMAALQicgAAgFZEDgAA0IrIAQAAWhE5AABAKyIHAABoReQAAACtiBwAAKAVkQMAALQicgAAgFZEDgAA0IrIAQAAWhE5AABAKyIHAABoReQAAACtiBwAAKAVkQMAALQicgAAgFZEDgAA0IrIAQAAWhE5AABAKyIHAABoReQAAACtiBwAAKAVkQMAALQicgAAgFZEDgAA0IrIAQAAWhE5AABAKyIHAABoReQAAACtiBwAAKAVkQMAALQicgAAgFZEDgAA0IrIAQAAWhE5AABAKyIHAABoReQAAACtiBwAAKAVkQMAALQicgAAgFZEDgAA0IrIAQAAWhE5AABAKyIHAABoReQAAACtiBwAAKAVkQMAALQicgAAgFZEDgAA0IrIAQAAWhE5AABAKyIHAABoReQAAACtiBwAAKAVkQMAALQicgAAgFZEDgAA0IrIAQAAWhE5AABAKyIHAABoZWGRU1Wvq6qPVdV3qurbi9oPAADARotcyblnkquS/PYC9wEAAHAnuxb1wmOM1ydJVV20qH0AAABs5j05AABAKwtbydmOqtqdZPeGTWtTzQIAAJyetrSSU1Vvrqpxgtt5d2Gei5PcuuF24114LQBYaYcOHZp6BFaEY42dZqsrOW9JcvkJHnPd9kZJkrwpySUb7q9F6ADAtuzZs2fqEVgRjjV2mi1FzhjjliS3LGiWjDGOJDmyfr+qFrUrAACgqYW9J6eq9ia5f5K9Se5eVU+Yf+tLY4zbF7VfAABgtS3ywgNvTPLiDff/5/zr05PsX+B+AQCAFbawS0iPMS4aY9RRbvsXtU8AAACfkwMAALQicgAAgFZEDgAA0IrIAQAAWhE5AABAKyIHAABoReQAAACtiBwAAKAVkQMAALQicgAAgFZEDgAA0IrIAQAAWhE5AABAKyIHAABoReQAAACtiBwAAKAVkQMAALQicgAAgFZEDgAA0IrIAQAAWhE5AABAKyIHAABoReQAAACtiBwAAKAVkQMAALQicgAAgFZEDgAA0IrIAQAAWhE5AABAKyIHAABoReQAAACtiBwAAKAVkQMAALQicgAAgFZEDgAA0IrIAQAAWhE5AABAKyIHAABoReQAAACtiBwAAKAVkQMAALQicgAAgFZEDgAA0IrIAQAAWhE5AABAKyIHAABoReQAAACtiBwAAKAVkQMAALQicgAAgFZEDgAA0IrIAQAAWhE5AABAKyIHAABoReQAAACtiBwAAKAVkQMAALQicgAAgFZEDgAA0MquqQcAJlI13b7HmG7fAEB7VnIAAIBWRA4AANCKyAEAAFoROQAAQCsiBwAAaEXkAAAArYgcAACgFZEDAAC0clp8GOi1116b4cMDT9ra2lqS5PDhwxNPcvpYW1vLvn37ph6DFXLw4EH/jW6B39e2bv3XDGAVnRaRc/755089AivgwIEDQoelOHjwYM4999ypx2AFvOc975l6BIBJOF0N5vwNMcviWAO6sXLITnNarOQAAFu3d+/eHDhwQFhvgVMjt84p3+xEIgcAGvOHT2AVOV0NAABoReQAAACtiBwAAKAVkQMAALQicgAAgFZEDgAA0IrIAQAAWhE5AABAKyIHAABoReQAAACtiBwAAKAVkQMAALQicgAAgFZEDgAA0IrIAQAAWhE5AABAK7umHgCYyBhTTwAAsBBWcgAAgFZEDgAA0IrIAQAAWhE5AABAKyIHAABoReQAAACtiBwAAKAVkQMAALQicgAAgFZEDgAA0IrIAQAAWhE5AABAKyIHAABoReQAAACtiBwAAKAVkQMAALQicgAAgFZEDgAA0IrIAQAAWhE5AABAKyIHAABoReQAAACtiBwAAKAVkQMAALQicgAAgFZEDgAA0IrIAQAAWhE5AABAKyIHAABoReQAAACtiBwAAKAVkQMAALQicgAAgFZEDgAA0IrIAQAAWhE5AABAKyIHAABoReQAAACtiBwAAKAVkQMAALQicgAAgFZEDgAA0IrIAQAAWhE5AABAKyIHAABoReQAAACtiBwAAKAVkQMAALQicgAAgFZEDgAA0MrCIqeqHl5V76iq66vqjqq6tqreUFX3XNQ+AQAAdi3wtc/LLKJeluRLSR6X5O1JzkjymgXuFwAAWGELi5wxxgeSfGDDpuuq6tFJXhGRAwAALMiy35NzVpJvLXmfAADAClnk6Wp3UlXnJHlVjrOKU1W7k+zesGlt0XMBAAC9bHklp6reXFXjBLfzNj3nYZmdunbVGOPtx3n5i5PcuuF241bng+06dOjQ1COwIhxrLItjDVhV21nJeUuSy0/wmOvW/6GqHprk6iQfS/LSEzzvTUku2XB/LUKHJdmzZ8/UI7AiHGssi2MNWFVbjpwxxi1JbjmZx85XcK5Ock2Sl4wxfnCC1z6S5MiG5291PAAAYMUt7D0588DZn+Qrmb0P54Hr0TLGuGlR+wUAAFbbIi888Mwk58xvm085s0QDAAAsxMIuIT3GuHyMUUe7LWqfAAAAy/6cHAAAgIUSOQAAQCsiBwAAaEXkAAAArYgcAACgFZEDAAC0InIAAIBWRA4AANCKyAEAAFoROQAAQCsiBwAAaEXkAAAArYgcAACgFZEDAAC0InIAAIBWRA4AANCKyAEAAFoROQAAQCsiBwAAaEXkAAAArYgcAACgFZEDAAC0InIAAIBWRA4AANCKyAEAAFoROQAAQCsiBwAAaEXkAAAArYgcAACgFZEDAAC0InIAAIBWRA4AANCKyAEAAFoROQAAQCsiBwAAaEXkAAAArYgcAACgFZEDAAC0InIAAIBWRA4AANCKyAEAAFoROQAAQCsiBwAAaEXkAAAArYgcAACgFZEDAAC0InIAAIBWRA4AANCKyAEAAFoROQAAQCsiBwAAaEXkAAAArYgcAACgFZEDAAC0InIAAIBWRA4AANCKyAEAAFoROQAAQCsiBwAAaEXkAAAArYgcAACgFZEDAAC0InIAAIBWRA4AANCKyAEAAFoROQAAQCsiBwAAaEXkAAAAreyaegDYKW6//fbcdtttU4/BCrj99tunHoEV4fc1oJOt/H5WY4wFjnLXVNXDktw49RwAAMCOcfYY42vHe8BOj5xK8tAkh6ee5TSzllkcnh2/diyWY41lcayxLI41lsWxtj1rSb4+ThAxO/p0tfnwx600ftisDZMkh8cYzlNgYRxrLItjjWVxrLEsjrVtO6lfKxceAAAAWhE5AABAKyKnpyNJ3jD/CovkWGNZHGssi2ONZXGsLdCOvvAAAADAVlnJAQAAWhE5AABAKyIHAABoReQAAACtiJzGqurhVfWOqrq+qu6oqmur6g1Vdc+pZ6OfqnpdVX2sqr5TVd+eeh76qKpXVtWXq+q7VfWJqnrS1DPRT1U9tareX1Vfr6pRVc+beib6qaqLq+pTVXW4qr5RVe+tqkdPPVdHIqe38zL7d/yyJI9N8itJXp7kN6YcirbumeSqJL899SD0UVUvTHJJZpdZPT/J55J8sKoeNOlgdHRGZsfXK6cehNaeluSyJE9O8swk90jyoao6Y9KpGnIJ6RVTVa9N8ooxxiOnnoWequqiJG8dY9x34lFooKo+keRTY4xfmt+/W5KvJnnbGOPNkw5HW1U1kjx/jPHeqWeht6p6YJJvJHnaGOMjU8/TiZWc1XNWkm9NPQTAicxPrX1ikj9d3zbG+MH8/lOmmgvgFDpr/tWfzU4xkbNCquqcJK9K8rtTzwJwEh6Q5O5Jbt60/eYkD1n+OACnznxl+q1JPjrG+PzE47Qjck5DVfXm+Zsij3c7b9NzHpbkA0muGmO8fZrJOd1s51gDAE7KZUkel+RFUw/S0a6pB2Bb3pLk8hM85rr1f6iqhya5OsnHkrx0cWPR0JaONTjFvpnk+0kevGn7g5PctPxxAE6Nqro0yXOSPHWMcePU83Qkck5DY4xbktxyMo+dr+BcneSaJC+Zn88OJ2UrxxqcamOM71XVNUmekeS9yf87veMZSS6dcDSAbamqSvK2JM9PcsEY4/qJR2pL5DQ2D5z9Sb6S5DVJHjj7bysZY/hbUE6pqtqb5P5J9ia5e1U9Yf6tL40xbp9sME53lyS5oqo+neSTSV6d2aV+3zXlUPRTVfdJcs6GTY+Y/z72rTHGDdNMRUOXJbkwyXOTHK6q9fcX3jrGuGO6sfpxCenG5pfyPeofBMYYtdxp6K6qLk/y4qN86+ljjP3LnYZOquqXkrw2s4sNfDbJL48xPjHpULRTVRdkdubDZleMMS5a6jC0Nb88+dG8ZIxx+TJn6U7kAAAArbi6GgAA0IrIAQAAWhE5AABAKyIHAABoReQAAACtiBwAAKAVkQMAALQicgAAgFZEDgAA0IrIAQAAWhE5AABAKyIHAABo5f8CuRCw8SwWSMUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: only try validation set\n",
    "idx = np.random.randint(len(RAW_DATA))\n",
    "current_pos, goal_pos, occ_grid, next_pos, _, _ = RAW_DATA[idx]\n",
    "predicted_pos = model.forward(dataset[idx][0].view(1, -1)).detach().cpu().numpy().flatten()\n",
    "visualize_data(occ_grid, current_pos, goal_pos, next_pos, predicted_pos=predicted_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562d898a",
   "metadata": {},
   "source": [
    "# Motion planning test\n",
    "\n",
    "Test dataset (100 sets):\n",
    "- Obstacles\n",
    "- Start\n",
    "- Goal\n",
    "- Path of astar\n",
    "\n",
    "Evaluation metric:\n",
    "- Sucess: close to the goal within a tolerance, path not in collision\n",
    "- Path length: "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
